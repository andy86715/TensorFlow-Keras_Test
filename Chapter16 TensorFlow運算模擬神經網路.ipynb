{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神經網路模擬公式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y = activation(X * W + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andy/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XWb =  [[-0.35999998  0.28      ]]\n",
      "y =  [[0.   0.28]]\n"
     ]
    }
   ],
   "source": [
    "# 激活函數activation使用relu\n",
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "W = tf.Variable([[-0.5, -0.2],\n",
    "                 [-0.3, 0.4 ],\n",
    "                 [-0.5, 0.2 ]])\n",
    "b = tf.Variable([[0.1, 0.2]])\n",
    "\n",
    "XWb = tf.matmul(X,W)+b\n",
    "y = tf.nn.relu(XWb)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('XWb = ', sess.run(XWb))\n",
    "    print('y = ', sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XWb =  [[-0.35999998  0.28      ]]\n",
      "y =  [[0.41095957 0.5695462 ]]\n"
     ]
    }
   ],
   "source": [
    "# 激活函數activation使用sigmoid\n",
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "W = tf.Variable([[-0.5, -0.2],\n",
    "                 [-0.3, 0.4 ],\n",
    "                 [-0.5, 0.2 ]])\n",
    "b = tf.Variable([[0.1, 0.2]])\n",
    "\n",
    "XWb = tf.matmul(X,W)+b\n",
    "y = tf.nn.sigmoid(XWb)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('XWb = ', sess.run(XWb))\n",
    "    print('y = ', sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[-0.21869557 -0.51793355]\n",
      " [ 1.2849728   0.23922022]\n",
      " [-2.20566     0.9302928 ]]\n",
      "b: [[-1.7342868  0.5754654]]\n",
      "y: [[0.        0.7882531]]\n"
     ]
    }
   ],
   "source": [
    "# 以常態分佈的亂數初始化Weight和Bias\n",
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "y = tf.nn.relu(tf.matmul(X,W)+b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    print('W:', sess.run(W))\n",
    "    print('b:', sess.run(b))\n",
    "    print('y:', sess.run(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[ 0.81867784 -0.47310334]\n",
      " [-1.0845878   0.02371043]\n",
      " [ 2.4391391  -0.09180546]]\n",
      "b: [[ 0.18670943 -1.6524714 ]]\n",
      "y: [[1.2729187 0.       ]]\n"
     ]
    }
   ],
   "source": [
    "# 縮減上述寫法，只執行一次session run\n",
    "X = tf.Variable([[0.4, 0.2, 0.4]])\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "y = tf.nn.relu(tf.matmul(X,W)+b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    (_b,_W,_y) = sess.run((b,W,y))\n",
    "    print('W:', _W)\n",
    "    print('b:', _b)\n",
    "    print('y:', _y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改以placeholder傳入x值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[-0.8493311  -1.4771539 ]\n",
      " [ 0.2618949   0.40300435]\n",
      " [-0.14252637 -0.0699286 ]]\n",
      "b: [[ 1.3195693  -0.15323608]]\n",
      "y: [[0.9752053 0.       ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = tf.placeholder(\"float\", [None, 3]) # 前面定義資料型態，後面代表矩陣大小\n",
    "W = tf.Variable(tf.random_normal([3, 2]))\n",
    "b = tf.Variable(tf.random_normal([1, 2]))\n",
    "y = tf.nn.relu(tf.matmul(X,W)+b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4, 0.2, 0.4]]) # 建立X_array\n",
    "    (_b,_W,_y) = sess.run((b,W,y), feed_dict={X:X_array})\n",
    "    print('W:', _W)\n",
    "    print('b:', _b)\n",
    "    print('y:', _y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立layer函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer(output_dim, input_dim, inputs, activation=None):\n",
    "    W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
    "    b = tf.Variable(tf.random_normal([1, output_dim]))\n",
    "    XWb = tf.matmul(inputs, W) + b\n",
    "    if activation is None: # 如果沒有傳入激活函數就不使用\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用layer函數建立3層神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 輸入層4個神經元\n",
    "X = tf.placeholder(\"float\", [None, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 隱藏層3個神經元\n",
    "h = layer(output_dim=3, input_dim=4, inputs=X, activation=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 輸出層2個神經元\n",
    "y = layer(output_dim=2, input_dim=3, inputs=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: [[0.4 0.2 0.4 0.5]]\n",
      "b: [[0.        2.0594077 0.       ]]\n",
      "y: [[2.0608597 0.948593 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4, 0.2, 0.4, 0.5]]) # 建立X_array\n",
    "    (layer_X, layer_h, layer_y) = sess.run((X,h,y), feed_dict={X:X_array})\n",
    "    print('W:', layer_X)\n",
    "    print('b:', layer_h)\n",
    "    print('y:', layer_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立layer_debug函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def layer_debug(output_dim, input_dim, inputs, activation=None):\n",
    "    W = tf.Variable(tf.random_normal([input_dim, output_dim]))\n",
    "    b = tf.Variable(tf.random_normal([1, output_dim]))\n",
    "    XWb = tf.matmul(inputs, W) + b\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "    return outputs, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Layer X:\n",
      "[[0.4 0.2 0.4 0.5]]\n",
      "W1:\n",
      "[[-0.957348   -0.43149352  0.45813298]\n",
      " [ 1.6596817  -1.1965383  -0.49768868]\n",
      " [-0.48003554 -0.5982234  -2.3496964 ]\n",
      " [-1.773955    0.07885315 -1.7832947 ]]\n",
      "b1:\n",
      "[[ 0.88200456  0.5969678  -2.423311  ]]\n",
      "hidden Layer h:\n",
      "[[0. 0. 0.]]\n",
      "W2:\n",
      "[[ 2.095088   -0.28963253]\n",
      " [ 1.4626018   1.2331222 ]\n",
      " [ 0.34808496  0.4087256 ]]\n",
      "b2:\n",
      "[[ 0.13241108 -0.29559785]]\n",
      "output Layer h:\n",
      "[[ 0.13241108 -0.29559785]]\n"
     ]
    }
   ],
   "source": [
    "# 輸入層4個神經元\n",
    "X = tf.placeholder(\"float\", [None, 4])\n",
    "\n",
    "# 隱藏層3個神經元\n",
    "h,W1,b1 = layer_debug(output_dim=3, input_dim=4, inputs=X, activation=tf.nn.relu)\n",
    "\n",
    "# 輸出層2個神經元\n",
    "y,W2,b2 = layer_debug(output_dim=2, input_dim=3, inputs=h)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    X_array = np.array([[0.4, 0.2, 0.4, 0.5]]) # 建立X_array\n",
    "    (layer_X, layer_h, layer_y, W1, b1, W2, b2) = sess.run((X,h,y,W1,b1,W2,b2), feed_dict={X:X_array})\n",
    "    print('input Layer X:');print(layer_X)\n",
    "    print('W1:');print(W1)\n",
    "    print('b1:');print(b1)\n",
    "    print('hidden Layer h:');print(layer_h)\n",
    "    print('W2:');print(W2)\n",
    "    print('b2:');print(b2)\n",
    "    print('output Layer h:');print(layer_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
